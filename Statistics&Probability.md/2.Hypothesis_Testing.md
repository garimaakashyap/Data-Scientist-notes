# Hypothesis Testing - Complete Guide

## Introduction
Hypothesis testing is a statistical method used to make decisions about populations based on sample data. It helps answer questions like "Is this new drug effective?" or "Do men and women earn different salaries?"

## 1. Basic Concepts

### What is Hypothesis Testing?
A systematic way to test claims or ideas about a population using sample data.

### Key Components

**1. Null Hypothesis (H₀):**
- The "status quo" or "no effect" hypothesis
- What we assume to be true initially
- Example: "The new drug has no effect" or "Men and women earn the same"

**2. Alternative Hypothesis (H₁ or Hₐ):**
- What we want to prove
- The opposite of null hypothesis
- Example: "The new drug is effective" or "Men and women earn different amounts"

**3. Test Statistic:**
- A number calculated from sample data
- Used to decide whether to reject H₀

**4. P-value:**
- Probability of observing the data (or more extreme) if H₀ is true
- **Small p-value** (< 0.05) → Reject H₀
- **Large p-value** (> 0.05) → Don't reject H₀

**5. Significance Level (α - alpha):**
- Threshold for making decisions
- Common values: 0.05 (5%), 0.01 (1%), 0.10 (10%)
- If p-value < α, reject H₀

### The Hypothesis Testing Process

```
1. State H₀ and H₁
2. Choose significance level (α)
3. Collect sample data
4. Calculate test statistic
5. Calculate p-value
6. Make decision:
   - If p < α: Reject H₀ (evidence supports H₁)
   - If p ≥ α: Fail to reject H₀ (not enough evidence)
7. Interpret results
```

## 2. Types of Tests

### One-Sample Tests

**Testing if sample mean equals a specific value**

**Example:** Is the average height 170 cm?

```
H₀: μ = 170
H₁: μ ≠ 170  (two-tailed)
   or
H₁: μ > 170  (one-tailed, right)
H₁: μ < 170  (one-tailed, left)
```

### Two-Sample Tests

**Testing if two groups are different**

**Example:** Do men and women have different salaries?

```
H₀: μ₁ = μ₂  (means are equal)
H₁: μ₁ ≠ μ₂  (means are different)
```

### Types of Alternative Hypotheses

**1. Two-tailed (≠):**
- Testing for any difference
- H₁: μ ≠ value
- More conservative

**2. One-tailed right (>):**
- Testing if value is greater
- H₁: μ > value

**3. One-tailed left (<):**
- Testing if value is less
- H₁: μ < value

## 3. Common Test Statistics

### Z-Test

**When to use:**
- Large sample size (n ≥ 30)
- Population standard deviation known
- Normal distribution

**Formula:**
```
z = (x̄ - μ₀) / (σ / √n)
```

Where:
- x̄ = sample mean
- μ₀ = hypothesized population mean
- σ = population standard deviation
- n = sample size

**Example:** Testing if average test score is 75

**Given:**
- Sample: n = 100, x̄ = 78, σ = 10
- H₀: μ = 75
- H₁: μ ≠ 75
- α = 0.05

**Solution:**
```
z = (78 - 75) / (10 / √100)
  = 3 / 1
  = 3.0
```

**Critical z-value** (two-tailed, α = 0.05) = ±1.96

**Decision:** |3.0| > 1.96 → **Reject H₀**

**Interpretation:** Evidence suggests average score is not 75.

### T-Test

**When to use:**
- Small sample size (n < 30)
- Population standard deviation unknown
- Normal distribution (approximately)

**Formula:**
```
t = (x̄ - μ₀) / (s / √n)
```

Where:
- s = sample standard deviation
- Uses t-distribution (depends on degrees of freedom = n-1)

**Example:** Testing if average weight is 70 kg

**Given:**
- Sample: n = 25, x̄ = 72, s = 5
- H₀: μ = 70
- H₁: μ ≠ 70
- α = 0.05

**Solution:**
```
t = (72 - 70) / (5 / √25)
  = 2 / 1
  = 2.0
```

**Degrees of freedom** = 25 - 1 = 24

**Critical t-value** (two-tailed, α = 0.05, df = 24) ≈ ±2.064

**Decision:** |2.0| < 2.064 → **Fail to reject H₀**

**Interpretation:** Not enough evidence that average weight differs from 70 kg.

### Python Code for T-Test

```python
from scipy import stats
import numpy as np

# Sample data
sample = [68, 70, 72, 71, 69, 73, 72, 70, 71, 72]
hypothesized_mean = 70

# One-sample t-test
t_statistic, p_value = stats.ttest_1samp(sample, hypothesized_mean)

print(f"t-statistic: {t_statistic:.4f}")
print(f"p-value: {p_value:.4f}")

# Decision
alpha = 0.05
if p_value < alpha:
    print("Reject H₀: Mean is significantly different from 70")
else:
    print("Fail to reject H₀: Not enough evidence")
```

## 4. Two-Sample T-Test

### Independent Samples T-Test

**Testing if two groups have different means**

**Example:** Do men and women earn different salaries?

**Given:**
- Men: n₁ = 30, x̄₁ = 55000, s₁ = 5000
- Women: n₂ = 25, x̄₂ = 52000, s₂ = 4500
- H₀: μ₁ = μ₂
- H₁: μ₁ ≠ μ₂
- α = 0.05

**Formula (equal variances assumed):**
```
t = (x̄₁ - x̄₂) / (sₚ × √(1/n₁ + 1/n₂))

where sₚ = pooled standard deviation
```

**Python Code:**
```python
from scipy import stats
import numpy as np

# Sample data
men_salaries = np.random.normal(55000, 5000, 30)
women_salaries = np.random.normal(52000, 4500, 25)

# Two-sample t-test
t_stat, p_value = stats.ttest_ind(men_salaries, women_salaries)

print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")

alpha = 0.05
if p_value < alpha:
    print("Reject H₀: Significant difference in salaries")
else:
    print("Fail to reject H₀: No significant difference")
```

### Paired T-Test

**Testing if there's a difference before and after treatment**

**Example:** Is a weight loss program effective?

**Given:**
- Before: [80, 85, 90, 75, 88]
- After: [78, 82, 87, 73, 85]
- H₀: μₐ = 0 (no difference)
- H₁: μₐ ≠ 0 (there is a difference)

**Python Code:**
```python
from scipy import stats

before = [80, 85, 90, 75, 88]
after = [78, 82, 87, 73, 85]

# Paired t-test
t_stat, p_value = stats.ttest_rel(before, after)

print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("Reject H₀: Program is effective")
else:
    print("Fail to reject H₀: Program not effective")
```

## 5. Understanding P-Values

### What is a P-Value?

**P-value** = Probability of observing the data (or more extreme) **if H₀ is true**.

### Interpreting P-Values

| P-Value | Interpretation |
|---------|----------------|
| **< 0.01** | Very strong evidence against H₀ |
| **0.01 - 0.05** | Strong evidence against H₀ |
| **0.05 - 0.10** | Weak evidence against H₀ |
| **> 0.10** | Little to no evidence against H₀ |

### Common Misconceptions

❌ **WRONG:** "P-value is the probability that H₀ is true"
✅ **CORRECT:** "P-value is the probability of data if H₀ is true"

❌ **WRONG:** "P-value tells us the effect size"
✅ **CORRECT:** "P-value tells us statistical significance, not practical importance"

### Example: Understanding P-Value

**Scenario:** Testing if a coin is fair (H₀: p = 0.5)

**Experiment:** Flip coin 100 times, get 60 heads

**P-value calculation:**
- If coin is fair, probability of getting 60+ heads ≈ 0.03
- **P-value = 0.03**

**Interpretation:**
- If coin is fair, there's only 3% chance of getting 60+ heads
- This is unlikely, so we reject H₀
- **Conclusion:** Coin appears to be biased

## 6. Type I and Type II Errors

### Type I Error (False Positive)

**Definition:** Rejecting H₀ when it's actually true

**Probability:** α (significance level)

**Example:**
- H₀: Drug has no effect
- We reject H₀ and say drug works
- But actually, drug has no effect
- **We made a mistake!**

**How to reduce:** Lower significance level (use α = 0.01 instead of 0.05)

### Type II Error (False Negative)

**Definition:** Failing to reject H₀ when it's actually false

**Probability:** β

**Example:**
- H₀: Drug has no effect
- We fail to reject H₀
- But actually, drug does work
- **We missed the effect!**

**How to reduce:** Increase sample size

### Power of Test

**Power = 1 - β**

Probability of correctly rejecting H₀ when it's false

**Higher power is better!**

### Summary Table

| Decision | H₀ is True | H₀ is False |
|----------|------------|-------------|
| **Reject H₀** | Type I Error (α) | ✅ Correct (Power) |
| **Don't Reject H₀** | ✅ Correct | Type II Error (β) |

## 7. Chi-Square Test

### Testing Categorical Data

**Example:** Is there a relationship between gender and job preference?

**Contingency Table:**
```
          Engineer  Teacher  Doctor
Male        20       10       15
Female      10       20       15
```

**H₀:** No relationship (independent)
**H₁:** There is a relationship (dependent)

**Python Code:**
```python
from scipy.stats import chi2_contingency
import numpy as np

# Contingency table
table = np.array([[20, 10, 15],
                 [10, 20, 15]])

chi2, p_value, dof, expected = chi2_contingency(table)

print(f"Chi-square statistic: {chi2:.4f}")
print(f"p-value: {p_value:.4f}")
print(f"Degrees of freedom: {dof}")

if p_value < 0.05:
    print("Reject H₀: There is a relationship")
else:
    print("Fail to reject H₀: No relationship")
```

## 8. ANOVA (Analysis of Variance)

### Testing Multiple Groups

**Example:** Do three teaching methods produce different test scores?

**H₀:** All group means are equal (μ₁ = μ₂ = μ₃)
**H₁:** At least one mean is different

**Python Code:**
```python
from scipy.stats import f_oneway

# Three groups
method_a = [85, 87, 86, 88, 84]
method_b = [90, 92, 91, 89, 93]
method_c = [78, 80, 79, 81, 77]

# One-way ANOVA
f_stat, p_value = f_oneway(method_a, method_b, method_c)

print(f"F-statistic: {f_stat:.4f}")
print(f"p-value: {p_value:.4f}")

if p_value < 0.05:
    print("Reject H₀: Methods produce different results")
else:
    print("Fail to reject H₀: No difference between methods")
```

## 9. Complete Example: Step-by-Step

### Problem: Is the new training program effective?

**Scenario:**
- Company wants to test if new training improves sales
- Before training: Average sales = $10,000
- After training 20 employees: Average sales = $11,500, STD = $2,000

**Step 1: State Hypotheses**
```
H₀: μ = 10,000 (no improvement)
H₁: μ > 10,000 (improvement)
```

**Step 2: Choose Significance Level**
```
α = 0.05
```

**Step 3: Calculate Test Statistic**
```
t = (x̄ - μ₀) / (s / √n)
t = (11,500 - 10,000) / (2,000 / √20)
t = 1,500 / (2,000 / 4.47)
t = 1,500 / 447.2
t = 3.35
```

**Step 4: Find Critical Value**
- Degrees of freedom = 20 - 1 = 19
- One-tailed test, α = 0.05
- Critical t-value ≈ 1.729

**Step 5: Make Decision**
```
3.35 > 1.729 → Reject H₀
```

**Step 6: Calculate P-Value**
```python
from scipy import stats
p_value = 1 - stats.t.cdf(3.35, df=19)
# p_value ≈ 0.0016
```

**Step 7: Interpret Results**
- P-value (0.0016) < α (0.05)
- **Conclusion:** Training program is effective!
- Average sales increased significantly

## 10. Assumptions of Tests

### T-Test Assumptions

1. **Random sampling:** Data collected randomly
2. **Independence:** Observations are independent
3. **Normality:** Data is approximately normal (or large sample)
4. **Equal variances:** For two-sample test (can use Welch's test if not)

### Checking Assumptions

```python
from scipy import stats
import numpy as np

# Check normality (Shapiro-Wilk test)
data = np.random.normal(100, 15, 30)
statistic, p_value = stats.shapiro(data)

if p_value > 0.05:
    print("Data appears normal")
else:
    print("Data may not be normal")
```

## 11. Effect Size

### Why Effect Size Matters

**P-value tells us:** Is there an effect?
**Effect size tells us:** How big is the effect?

### Cohen's d (Effect Size for T-Test)

**Formula:**
```
d = (x̄₁ - x̄₂) / sₚ
```

**Interpretation:**
- **d = 0.2:** Small effect
- **d = 0.5:** Medium effect
- **d = 0.8:** Large effect

**Example:**
```
Men: x̄ = 55,000
Women: x̄ = 52,000
Pooled STD: sₚ = 5,000

d = (55,000 - 52,000) / 5,000
d = 0.6 (Medium effect)
```

**Python Code:**
```python
def cohens_d(group1, group2):
    n1, n2 = len(group1), len(group2)
    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))
    return (np.mean(group1) - np.mean(group2)) / pooled_std

d = cohens_d(men_salaries, women_salaries)
print(f"Cohen's d: {d:.4f}")
```

## 12. Common Mistakes

### Mistake 1: Confusing Statistical and Practical Significance
- **Statistical significance:** P-value < 0.05
- **Practical significance:** Effect size matters in real world
- **Example:** Very small difference can be statistically significant with large sample

### Mistake 2: Multiple Testing Problem
- Testing many hypotheses increases chance of Type I error
- **Solution:** Use Bonferroni correction or adjust α

### Mistake 3: Data Dredging
- Testing many hypotheses and only reporting significant ones
- **Solution:** Pre-specify hypotheses before looking at data

### Mistake 4: Misinterpreting "Fail to Reject"
- Doesn't mean H₀ is true!
- Just means "not enough evidence to reject"

## Key Takeaways

1. **H₀** = Status quo, what we test against
2. **H₁** = What we want to prove
3. **P-value < α** → Reject H₀ (evidence supports H₁)
4. **Type I Error** = False positive (reject true H₀)
5. **Type II Error** = False negative (fail to reject false H₀)
6. **Effect size** matters, not just p-value
7. **Check assumptions** before running tests
8. **Statistical significance ≠ Practical importance**
9. **T-test** for means, **Chi-square** for categories
10. **Always interpret results** in context

## Quick Reference

| Test | Use When | H₀ |
|------|----------|-----|
| **One-sample t-test** | Compare sample mean to known value | μ = value |
| **Two-sample t-test** | Compare two independent groups | μ₁ = μ₂ |
| **Paired t-test** | Compare before/after | μₐ = 0 |
| **Chi-square** | Test categorical relationships | Variables independent |
| **ANOVA** | Compare multiple groups | All means equal |

**Decision Rule:**
- **P-value < α** → Reject H₀
- **P-value ≥ α** → Fail to reject H₀

