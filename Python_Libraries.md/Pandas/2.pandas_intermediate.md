# Pandas Intermediate - Step by Step

## 1. Advanced Indexing

### Setting Index
```python
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'Salary': [50000, 60000, 70000]
})

# Set Name as index
df_indexed = df.set_index('Name')
print(df_indexed)
#          Age  Salary
# Name                
# Alice     25   50000
# Bob       30   60000
# Charlie   35   70000

# Reset index
df_reset = df_indexed.reset_index()
```

### Multi-level Indexing
```python
# Create multi-index
arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]
index = pd.MultiIndex.from_arrays(arrays, names=('Group', 'Number'))
df = pd.DataFrame({'Value': [10, 20, 30, 40]}, index=index)
print(df)
#              Value
# Group Number      
# A     1         10
#       2         20
# B     1         30
#       2         40

# Access multi-index
print(df.loc['A'])
print(df.loc[('A', 1)])
```

## 2. Advanced Filtering

### Query Method
```python
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'Age': [25, 30, 35, 28],
    'Salary': [50000, 60000, 70000, 55000]
})

# Using query (more readable)
result = df.query('Age > 30 and Salary > 60000')
print(result)

# Using variables in query
min_age = 30
result = df.query('Age > @min_age')
```

### String Methods
```python
df = pd.DataFrame({
    'Name': ['Alice Smith', 'Bob Johnson', 'Charlie Brown'],
    'Email': ['alice@email.com', 'bob@email.com', 'charlie@email.com']
})

# Extract domain from email
df['Domain'] = df['Email'].str.split('@').str[1]

# Replace text
df['Name'] = df['Name'].str.replace(' ', '_')

# Extract patterns (regex)
df['First_Name'] = df['Name'].str.extract(r'^(\w+)')
```

## 3. Data Transformation

### Apply Functions
```python
df = pd.DataFrame({'Numbers': [1, 2, 3, 4, 5]})

# Apply to each element
df['Squared'] = df['Numbers'].apply(lambda x: x ** 2)

# Apply to each row
df['Sum'] = df.apply(lambda row: row['Numbers'] + row['Squared'], axis=1)

# Apply to each column
df.apply(lambda col: col.sum(), axis=0)
```

### Map and Replace
```python
# Map values
df = pd.DataFrame({'Grade': ['A', 'B', 'C', 'A', 'B']})
grade_map = {'A': 4, 'B': 3, 'C': 2}
df['Points'] = df['Grade'].map(grade_map)

# Replace values
df['Grade'] = df['Grade'].replace({'A': 'Excellent', 'B': 'Good'})
```

### Pivot Tables
```python
df = pd.DataFrame({
    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],
    'Product': ['A', 'B', 'A', 'B'],
    'Sales': [100, 200, 150, 250]
})

# Create pivot table
pivot = df.pivot_table(values='Sales', index='Date', columns='Product', aggfunc='sum')
print(pivot)
# Product      A    B
# Date               
# 2024-01-01  100  200
# 2024-01-02  150  250
```

## 4. Merging and Joining DataFrames

### Merge (like SQL JOIN)
```python
df1 = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana']
})

df2 = pd.DataFrame({
    'ID': [1, 2, 3, 5],
    'Salary': [50000, 60000, 70000, 80000]
})

# Inner join (default)
merged = pd.merge(df1, df2, on='ID')
print(merged)

# Left join
merged_left = pd.merge(df1, df2, on='ID', how='left')

# Right join
merged_right = pd.merge(df1, df2, on='ID', how='right')

# Outer join (all records)
merged_outer = pd.merge(df1, df2, on='ID', how='outer')
```

### Concatenate
```python
df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})

# Stack vertically
combined = pd.concat([df1, df2], ignore_index=True)
print(combined)

# Stack horizontally
combined_h = pd.concat([df1, df2], axis=1)
```

## 5. Advanced Grouping

### GroupBy with Multiple Functions
```python
df = pd.DataFrame({
    'Department': ['IT', 'IT', 'HR', 'HR', 'IT'],
    'Employee': ['A', 'B', 'C', 'D', 'E'],
    'Salary': [50000, 60000, 45000, 50000, 55000]
})

# Multiple aggregations
grouped = df.groupby('Department')['Salary'].agg(['mean', 'sum', 'count', 'std'])
print(grouped)

# Custom aggregation
def salary_range(x):
    return x.max() - x.min()

grouped = df.groupby('Department')['Salary'].agg(['mean', salary_range])
```

### Transform (add aggregated values back)
```python
# Add mean salary per department to each row
df['Dept_Mean'] = df.groupby('Department')['Salary'].transform('mean')
print(df)
```

### Filter Groups
```python
# Keep only departments with more than 2 employees
filtered = df.groupby('Department').filter(lambda x: len(x) > 2)
print(filtered)
```

## 6. Time Series Operations

### Working with Dates
```python
# Create date range
dates = pd.date_range('2024-01-01', periods=5, freq='D')
df = pd.DataFrame({'Date': dates, 'Value': [10, 20, 30, 40, 50]})

# Set date as index
df = df.set_index('Date')

# Extract date parts
df['Year'] = df.index.year
df['Month'] = df.index.month
df['Day'] = df.index.day
df['Weekday'] = df.index.day_name()

# Resample (aggregate by time period)
daily = df.resample('W').sum()  # Weekly sum
```

### Shifting Data
```python
df = pd.DataFrame({'Value': [10, 20, 30, 40, 50]})

# Shift down (previous value)
df['Previous'] = df['Value'].shift(1)

# Shift up (next value)
df['Next'] = df['Value'].shift(-1)

# Calculate difference
df['Diff'] = df['Value'].diff()
```

## 7. Handling Duplicates

```python
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],
    'Age': [25, 30, 25, 35, 30]
})

# Find duplicates
print(df.duplicated())

# Remove duplicates
df_unique = df.drop_duplicates()

# Keep first/last occurrence
df_first = df.drop_duplicates(keep='first')
df_last = df.drop_duplicates(keep='last')
```

## 8. Categorical Data

```python
# Convert to categorical (saves memory)
df = pd.DataFrame({'Grade': ['A', 'B', 'C', 'A', 'B']})
df['Grade'] = df['Grade'].astype('category')

# Ordered categories
df['Grade'] = pd.Categorical(df['Grade'], categories=['C', 'B', 'A'], ordered=True)

# Get categories
print(df['Grade'].cat.categories)
```

## 9. Window Functions

### Rolling Window
```python
df = pd.DataFrame({'Value': [10, 20, 30, 40, 50, 60, 70]})

# Rolling mean (moving average)
df['Rolling_Mean'] = df['Value'].rolling(window=3).mean()

# Rolling sum
df['Rolling_Sum'] = df['Value'].rolling(window=3).sum()

# Expanding window (cumulative)
df['Expanding_Mean'] = df['Value'].expanding().mean()
```

## 10. Advanced Data Cleaning

### Handling Outliers
```python
df = pd.DataFrame({'Values': [1, 2, 3, 100, 4, 5, 6]})

# Using IQR method
Q1 = df['Values'].quantile(0.25)
Q3 = df['Values'].quantile(0.75)
IQR = Q3 - Q1

# Remove outliers
df_clean = df[(df['Values'] >= Q1 - 1.5*IQR) & (df['Values'] <= Q3 + 1.5*IQR)]
```

### Data Type Conversion
```python
# Convert types
df['Age'] = df['Age'].astype('int64')
df['Salary'] = df['Salary'].astype('float64')

# Convert to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Convert to numeric (handles errors)
df['Price'] = pd.to_numeric(df['Price'], errors='coerce')
```

## 11. Cross Tabulation

```python
df = pd.DataFrame({
    'Department': ['IT', 'IT', 'HR', 'HR', 'IT'],
    'Status': ['Active', 'Active', 'Inactive', 'Active', 'Active']
})

# Create crosstab
crosstab = pd.crosstab(df['Department'], df['Status'])
print(crosstab)

# With margins
crosstab = pd.crosstab(df['Department'], df['Status'], margins=True)
```

## Key Takeaways
- Use `merge()` to combine DataFrames (like SQL JOIN)
- `groupby()` is powerful for aggregations
- Time series operations help analyze trends
- Window functions calculate moving statistics
- Categorical data saves memory and improves performance

